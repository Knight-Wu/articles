## 吴桐的简历
## 联系方式
- 手机：17688748581
- Email：1239562508guge@gmail.com 


## 个人信息

 - 吴桐/男/1993.8 
 - 本科/东南大学/软件工程，2016.7毕业
 - 工作年限六年
 - github: https://github.com/Knight-Wu

## 能力
> 维护了一个博客, 总结了一些经验和知识: https://github.com/Knight-Wu/articles, 能熟练使用并清楚大部分原理, 包括es, kafka, spark, hdfs; 能快速上手常用的技术; 具备大数据环境下较强的故障追踪能力和调优经验, 给数仓解决过多个生产问题。熟练使用java，golang，具有丰富的高并发的开发经验; 强烈求知欲和对工作负责的态度，善于在工作解决实际问题和异常，善于读源码发现根本问题。可流畅阅读英文文档并使用英文写作。对 bitcoin 原理有所研究。


<br />
<br />

## 工作经历

### Shopee - 虾皮信息科技有限公司 （ 2019 年 五月 ~  至今, 2021 年度绩效 A ）
2019 年 五月到 2021 年九月在 seller 当大数据后台开发，主要开发了后三个项目。2021 年九月至今，在日志平台当后台开发，主要开发了前四个项目；
#### 重构日志平台
重构的原因是 elastic stack（以下简称ELK）架构下机器成本太高，es 集群大规模下有很多问题，以及原先架构的一些历史问题。组件除了对象存储全部从零开发，每天新增日志数据量 4PB，新架构在不改变用户需求和数据量不变的基础上只用了原架构三分之一的机器数量。简要描述一下架构，agent 采集日志后发送到kafka，indexer 消费，流式累积一批日志形成一个chunk 写入公司自研对象存储，发送 chunk 的元信息（所属业务，日志的开始时间和结束时间等）到元数据kafka，metaSvr 消费元数据kafka 构建chunk 的元信息写入es；查询时前端通过websocket 与 queryMaster 连接，querymaster 将自研的类似linux 管道的 pipeline search 查询语句转换为逻辑执行计划发送给queryWorker，整个查询过程均是流式返回，queryWorker 查询元信息es 过滤大部分chunk，再将关键字发送给indexSeach，indexSearch 分词后查询索引，返回chunkId 列表给queryWorker，queryWorker 匹配日志原文后发送给 queryMaster 做聚合。

1. 负责设计和开发 indexer，indexer 从 kafka 接收日志，按照列式存储的格式流式写入，每个列都支持流式编码写入, 相比累积一批原始日志数据在内存中再写入，大大降低占用的内存。chunk 存到公司自研对象存储。多线程高并发写入，内部采用buffer 链表缓存数据，减少数据的互相拷贝。单核写入带宽相比ELK 提升了四倍, 压缩率比从原来 es 的 1:1 提升到 1:6。
2. chunk 采用列式存储，提高查询效率，参考了apache parquet的编码格式，不同数据采用不同的编码方式，日志原文采用流式压缩和delta length 编码长度，时间戳采用delta length 编码，日志级别采用字典编码和游程编码相结合。
3. 写入过程中分词构建索引。通过查询的关键字分词后返回所属的chunkId。索引分为自研bloom 和基于lucene fst 结构自研的（以下简称fst）两种。自研 bloom 支持无锁多线程写入，内部采用线程安全的字节数组的相比 guava 的bloom 序列化反序列化时间少了百分之三十，大小只有原始日志数据的 0.1% 。fst 类似lucene 的倒排索引，分为前缀查找和不前缀两种，相比于bloom 不会产生fpp，但是大小是bloom 的五倍。相比 es 的重量级索引，增大了查询扫描的数据量却大大减少了存储的数据和写入时的计算开销，增大的查询数据量在流式查询并返回的架构下，用户感知到的查询时间并没有增加。
4. 由于indexer 会缓存一定大小的数据在内存中，所以要支持这部分数据可实时查询。由于indexer 采用k8s 部署，直接查询需要知道ip 和port，比较麻烦。采用indexer 建立grpc stream 连接，双向通信的方式，上游发送请求，indexer 流式返回，还解决了跨nginx 时的超时和数据包大小等rpc 异常。
5. 由于采用的索引粒度比较粗，搜常用词时可能会需要扫描大量数据，还支持对用户自定义字段单独建索引，索引信息保存在元数据es，在不读取chunk 前能提前过滤。
6. 负责设计和开发 indexSearch，查询引擎调用 index-search 查询 bloom 或 fst 进行过滤, 返回分词后每个词所在的 chunk 的列表，索引数据缓存在本地磁盘加速搜索。采用一致性hash 保证同一个索引id 都会落到同一台机器的缓存上。同时消费元信息kafka 保证新的数据有更大的概率在缓存中。

#### es 集群采用节点组合算法负载均衡
1. 背景是es 目前是按照shard 个数分配到各个es 节点，有可能因为不同索引间shard 写入压力不一致，业务流量暴涨等原因造成es 写入节点cpu 暴涨，各节点负载不均衡的情况。
2. 第一版采用根据es 节点写入压力的算法，每次选择最小写入压力的节点，但是无法解决由于业务突增导致的节点压力突增，从而不均衡。
3. 第二版采用节点组合的算法，一台机器通常部署四个 es 节点，每台机器抽出一个节点，构成4，8，12，4n 个节点的组，将不均衡情况平均到了组内各个节点，并结合第一版的根据写入压力来进行相同节点数的组间的选择，在流量突增时选择更多节点的group 进行扩容，从而使节点负载基本均衡。

#### 维护存储日志数据的 es 集群
1. es 作为之前elastic stack 的存储引擎, 承载公司所有业务7 到 15 天的日志量, 日增数据量 4PB, 大大小小有十几个集群, 由于之前架构的一些历史问题, 加上es 在大量数据量情况下的一些瓶颈, 解决了很多问题, 并做了一些优化. 
2. 由于es 单master 的架构，由于clusterState 结构体导致多数任务是单线程计算，某些任务在shard 数量过多时，计算很慢，拖慢了其他任务，通过修改源码，降低了某些任务的时间复杂度，是之前的十分之一。
3. 由于索引数过多，shard 数量过多，会导致master 任务积压，整个集群很慢的情况，通过减少某些不必要的master 任务，合并shard等手段解决。
4. 批量写入es 时，一批数据采用一个随机key 作为路由key，这批数据只会写入某个数据节点，避免写入多个数据节点时某个节点过慢导致写入总体时间变长的情况。

#### Spark Monitor
1. 通过 exporter 收集 spark 原生的指标到 prometheus 监控，可以查看spark 应用运行过程中的 cpu，memory和 spark 内置指标, 了解 spark 应用执行的情况.
2. 修改 spark 源码，监控增加了应用名和机器名等字段，可以按照应用和机器维度指标聚合，方便对比应用的每天执行情况等，查看某些耗时高于平均的机器等。

#### Business Insight
1. 类似于淘宝的生意参谋，给卖家提供数据分析和报表，例如 GMV 和销量等。
2. 负责从 Kafka 获取实时数据并写入 redis，提供实时查询；从 ElasticSearch 获取历史数据，数仓负责写入，提供历史的聚合查询，例如过去三十天等。

### 招联消费金融有限公司 （ 2016 年 7 月 ~ 2019 年 5 月 ）
#### 维护大数据集群
1. 负责生产和测试环境大数据集群的日常维护, 配置调优，保证集群的高可用性和高性能, 解决了公司基础数据组使用hive on spark跑批时的数个生产故障。
2. 多个问题的排查过程记录在个人github 。

#### 数据应用等系统
1. 使用 spark，hbase，hive 给客户营销系统做客群筛选和数据营销，提供离线和准实时查询。

#### 公司级的基础框架
1. 基于 dubbo 封装的远程调用框架，增加了一些功能提高可用性，下面描述两个功能。
2. 功能一，dubbo 默认的容错策略在提供者进程假死，例如线程池等资源耗尽，仍然会有少部分请求进入假死实例。改动后，提供者返回不能重试的异常时，后续请求不会发送，并持续发送心跳探测，当提供者恢复之后，缓慢增加请求。
3. 功能二，基于响应时间、请求数和异常等指标打分，构建基于分数的负载均衡策略，每次消费者选择提供者时选择打分最低（负载最低）的实例进行请求。


> Written with [StackEdit](https://stackedit.io/).
