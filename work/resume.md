### 吴桐的简历
### 联系方式
- 手机：17688748581
- Email：1239562508guge@gmail.com 


### 个人信息

 - 吴桐/男/1993.8 
 - 本科/东南大学/软件工程，2016.7毕业
 - 工作年限六年
 - github: https://github.com/Knight-Wu

### 能力
> 维护了一个博客, 总结了一些经验和知识: https://github.com/Knight-Wu/articles, 能熟练使用并清楚大部分原理, 包括es, kafka, spark, hdfs; 能快速上手常用的技术; 具备大数据环境下较强的故障追踪能力和调优经验, 给数仓解决过多个生产问题。熟练使用java，golang，具有丰富的高并发的开发经验; 强烈求知欲和对工作负责的态度，善于在工作解决实际问题和异常，善于读源码发现根本问题。可流畅阅读英文文档并使用英文写作。对 bitcoin 原理有所研究。


<br />
<br />

### 工作经历

#### Shopee - 虾皮信息科技有限公司 （ 2019 年 七月 ~  至今, 2021 年度绩效 A ）
2019 年 五月到 2021 年九月在 seller 当大数据后台开发，主要开发了后三个项目。2021 年九月至今，在日志平台当后台开发，主要开发了前四个项目；
##### 重构日志平台
重构的原因是 elastic stack（以下简称ELK）架构下机器成本太高，es 集群大规模下有很多问题，以及原先架构的一些历史问题。组件除了对象存储全部从零开发，每天新增日志数据量 4PB，新架构在不改变用户需求和数据量不变的基础上只用了原架构三分之一的机器数量。简要描述一下架构，agent 采集日志后发送到kafka，indexer 消费，流式累积一批日志形成一个chunk 写入公司自研对象存储，发送 chunk 的元信息（所属业务，日志的开始时间和结束时间等）到元数据kafka，metaSvr 消费元数据kafka 构建chunk 的元信息写入es；查询时前端通过websocket 与 queryMaster 连接，querymaster 将自研的类似linux 管道的 pipeline search 查询语句转换为逻辑执行计划发送给queryWorker，整个查询过程均是流式返回，queryWorker 查询元信息es 过滤大部分chunk，再将关键字发送给indexSeach，indexSearch 分词后查询索引，返回chunkId 列表给queryWorker，queryWorker 匹配日志原文后发送给 queryMaster 做聚合。

1. 负责设计和开发 indexer，indexer 从 kafka 接收日志，按照列式存储的格式流式写入，每个列都支持流式编码写入, 相比累积一批原始日志数据在内存中再写入，大大降低占用的内存。chunk 存到公司自研对象存储。多线程高并发写入，单核写入带宽相比ELK 提升了四倍, 压缩率比从原来 es 的 1:1 提升到 1:6。
2. 写入过程中分词构建索引。通过查询的关键字分词后返回所属的chunkId。索引分为自研bloom 和基于lucene fst 结构自研的（以下简称fst）两种。自研 bloom 支持无锁多线程写入，通过零拷贝和内部字节数组的数据结构相比 guava 的bloom 序列化反序列化时间少了百分之三十，大小只有原始日志数据的 0.1% 。fst 类似lucene 的倒排索引，分为前缀查找和不前缀两种，相比于bloom 不会产生fpp，但是大小是bloom 的五倍。相比 es 的重量级索引，增大了查询扫描的数据量却大大减少了存储的数据和写入时的计算开销，增大的查询数据量在流式查询并返回的架构下，用户感知到的查询时间并没有增加。
3. 负责设计和开发 indexSearch，查询引擎调用 index-search 查询 bloom 或 fst 进行过滤, 返回分词后每个词所在的 chunk 的列表，索引数据缓存在本地磁盘加速搜索。采用一致性hash 保证同一个索引id 都会落到同一台机器的缓存上。同时消费元信息kafka 保证新的数据有更大的概率在缓存中。
4. 实时查询
5. 用户自定义索引



##### es 集群采用节点组合算法负载均衡
1. 各个 es 节点因为写入的业务日志流量不均导致负载差别大，cpu 负载很不均衡，一开始采用基于历史监控数据的预测算法，根据写入lag 难以预计流量的突增，cpu 还是有飙升导致不均衡。后面采用基于节点组合的算法，一台机器通常部署四个 es 节点，每台机器抽出一个节点构成一个组，有 4，8，12，4n 个节点的组，将不均衡情况分散到组间，大大减少了不均衡的情况的方差。

##### processor 自动调度
1. processor 作为原日志平台接收 kafka 写入 es 集群的组件，之前缺少应对突发流量和业务增长的自动调度能力，通过日志流量的历史监控数据和 kafka lag 判断是否需要扩容。
2. 采用类似数据库快照技术解决多实例主备切换时的并发问题。

#### 维护存储日志数据的 es 集群
1. es 作为之前elastic stack 的存储引擎, 承载公司所有业务7 到 15 天的日志量, 日增数据量 4PB, 大大小小有十几个集群, 由于之前架构的一些历史问题, 加上es 在大量数据量情况下的一些瓶颈, 解决了很多问题, 并做了一些优化. 
2. 解决的问题包括master 计算过慢; shard数量过多; 写入速度不稳定; 查询大数据量过慢等问题. 

##### Sinker
 1.  是一个接收 Kafka 写入 Hdfs 的 exactly once 组件，解决了 Flume 在处理大数据量的时候经常会有百分之十的数据丢失和文件 EOF 等长达半年没解决的问题，能容忍 hdfs 和 kafka 集群异常，大促期间每天数据 100TB，上线的一年时间里没有出现过数据量过多或过少的问题

##### Spark Monitor
1. 通过 exporter 收集 spark 原生的指标到 prometheus 监控，可以查看spark 应用运行过程中的 cpu，memory，spark 内置指标, 了解 spark 应用执行的情况.
2. 修改 spark 源码，监控增加了应用名和机器名等字段，可以按照应用和机器维度指标聚合，方便对比应用的每天执行情况等，查看某些耗时高于平均的机器等。

##### Business Insight
1. 类似于淘宝的生意参谋，给卖家提供数据分析和报表，例如 GMV 和销量等。
2. 负责从 Kafka 获取实时数据并写入 redis，提供实时查询；从 ElasticSearch 获取历史数据，数仓负责写入，提供历史的聚合查询，例如过去三十天等。

#### 招联消费金融有限公司 （ 2016 年 7 月 ~ 2019 年 5 月 ）
主要使用 Java
##### 维护大数据集群
1. 负责生产和测试环境大数据集群的日常维护, 配置调优，保证集群的高可用性和高性能, 解决了公司基础数据组使用hive on spark跑批时的数个生产故障

##### 数据应用等系统
1. 使用 spark，hbase，hive 给客户营销系统做客群筛选和数据营销，提供离线和准实时查询。

##### 公司级的基础框架
1. 基于 dubbo 封装的远程调用框架，增加了基于分数的负载均衡、模拟正常请求的心跳并返回提供者信息等功能


> Written with [StackEdit](https://stackedit.io/).
