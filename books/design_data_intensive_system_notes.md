# chapter2_数据模型
## 何为关系型

数据被组织成关系，每个关系是数据中行的无序集合，
在数据库和在编程内存中或者磁盘上只是数据模型的不同，orm就是object relation mapping 用作数据模型的映射

下图很好的表达了关系的意思, 通过id 去关联
![image](https://user-images.githubusercontent.com/20329409/212015949-352ac261-8f80-4091-805e-0cac41991d40.png)

* NOSQL 

指的是not only sql


## 文档数据库
简单来说就是存储文档的数据库, 文档例如json


* 文档 schema
文档数据库有时称为无模式（schemaless），但这具有误导性，因为读取数据的代码通常假
定某种结构——即存在隐式模式，但不由数据库强制执行.
一个更精确的术语是读时
模式（schema-on-read）（数据的结构是隐含的，只有在数据被读取时才被解释），相应的
是写时模式（schema-on-write）（传统的关系数据库方法中，模式明确，且数据库确保所
有的数据都符合其模式）

* 文档数据库的优势
schema 灵活; 相关的数据可以就近读取; 与应用端组织数据的方式更加相似
  
* 文档数据库的劣势

表达多对多关系不太合适, 例如学生和课程, 当然也可以通过学生文档通过链接的形式跳转到课程文档的链接, join 也可以通过这样实现. 

* json 

类似一颗多叉树

![image](https://user-images.githubusercontent.com/20329409/212016110-9b265c6e-5f60-4b6a-b9a5-8101b3607d0c.png)

json 和 xml , csv 等原生不能表达二进制数据, 均用 Unicode, 占用空间, 且均有一些不够兼容的小问题, 例如 xml 和 csv 无法区分数字和仅有数字代表的字符串, 
json 没有命名空间的概念, 相同的字段无法表达

## 文档数据库和关系型数据库的区别, 没解决, 到底区别在哪

但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这
两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为外键，
在文档模型中称为文档引用; 但是文档数据库不利于多对多的表达, 会有很多冗余, 关系型数据库用id 来表示减少了很多存储. 

* 文档数据库和关系型数据库的融合

感觉目前市面上多数数据库都是文档数据库和关系型数据库的融合, 只是侧重不同, 偏于文档数据库的就类似nosql, 对于格式要求宽松, 方便更改格式

如果一个数据库能够处理类似文档的数据，并能够对其执行关系查询，那么应用
程序就可以使用最符合其需求的功能组合。
关系模型和文档模型的混合是未来数据库一条很好的路线。
. Codd对关系模型的原始描述实际上允许在关系模式中与JSON文档非常相似。他
称之为非简单域（nonsimple domains）。这个想法是，一行中的值不一定是一个像数
字或字符串一样的原始数据类型，也可以是一个嵌套的关系（表），因此可以把一个任
意嵌套的树结构作为一个值，这很像30年后添加到SQL中的JSON或XML支持

## Tips
* 存储城市等字符串信息时，为什么要加个id呢，因为像编码一样更容易修改，id像一个引用，最终文本只存在一个地方，只修改一个地方; 防止重复; 方便编码, 用id 即可存储在一个国家的所有城市, 表示这层信息

* 多对多关系 

增加一张中间表. 例如学生和课程

## 兼容

向后兼容(back compatibility): 指的是新的代码能兼容旧的数据. 
向前兼容(forward compatibility): 旧代码能兼容新数据, 主语都是代码或程序

* 数据库的查询优化器类似于得出一个遍历数据的路径


在关系数据库中，查询优化器自动决定查询的哪些部分以哪个顺序执行，以及使用哪些索
引。这些选择实际上是“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，
如下图:
![image](https://user-images.githubusercontent.com/20329409/212016529-7bae9bde-84ae-4cd5-9fa8-3ac5aaa3201e.png)



* 为什么有些数据库修改数据很慢

大型表上运行 UPDATE 语句在任何数据库上都可能会很慢，因为每一行都需要重写。要是不可
接受的话，应用程序可以将 first_name 设置为默认值 NULL ，并在读取时再填充，就像使用
文档数据库一样。

* 查询局部性

查询的东西都在一个地方, 能一次性返回, 减少IO
* 一对多可以用树状结构表示

多对多关系是不同数据模型之间具有区别性的重要特征。如果你的应用程
序大多数的关系是一对多关系（树状结构化数据），或者大多数记录之间不存在关系，那么
使用文档模型是合适的。
## 编码

### Thrift , Protocol Buffer
* 编码中如何压缩
int64 不一定占用八字节, 将每个字节的首位用于标识是否还有下一字节, 

* 如何向前兼容和向后兼容
向前兼容: 旧代码读新数据, 新数据中包含一个新的字段, 用一个新的 tag, 旧代码使用的是旧的 schema 不会识别出新的 tag , 即忽略新的字段
向后兼容: 新代码读取老数据, 新的 schema 的改动不能引起读取老数据的错误, 新的 schema 新加一个 tag (字段) ,旧的数据没有故读不到, 但是不能改变旧字段, 所以建议字段均是 optional(防止改成 required 校验失败), 删除字段意味着新代码不会读到旧代码的相关字段而已,
如果 tag 不变, 改变数据类型则需要考虑兼容, 否则会出现截断或数据丢失的风险. 

### Avro
TODO : avro 编码的图片

encoded bytes 并不包含 schema name 等, 也不包含指定 schema tag, 所以 writer schema 和 reader schema 必须要完全compatibility ; reader schema 通过 field name 找到 writer schema 对应的 field, 故通常来说不能改 field name, 但是可以在新的 schema 设置某一个field 为旧 schema 的 alias, 提供backward compatibility;

* 那么 writer schema 如何让 reader 知道呢? 
1. Large file with lots of records , include writer schema at the beginning of the file
2. Database with individually written records, match record with schema with schema version
3. Sending records over a network connection, 通过 avro RPC 框架, 在 conn 建立的时候指定 schema , 并用在整个 conn 的过程中

# chapter3_数据的存储格式和检索
**一开始引入的问题是如何存储 key val,**
## 最简单的模型, hash index and append only file
hash index: key, value(实际val 在文件中字节的偏移量)
append file: 一开始一直往一个文件里面 append, append 到一定大小, 进行文件 compaction, 只保留最新一个 key 的 val, 形成一个 segment, 然后可以在后台线程进行多个 segments 的合并, 合并完成之后再切换读和写, 并删除合并前的文件. 

* crash recovery

可以存储 hash index 的 snapshot 在磁盘上, 避免 crash 之后重新扫描文件, 否则崩溃恢复是不可接受的, 非常慢. 

* 如何删除某个key

在hash index 上更新val 为特殊标记

* 如何防止磁盘空间用满呢

按照一定大小组织磁盘的文件, 超过就新建一个文件, 然后定期合并, 相同key 保留更新的val, 然后删除旧的文件

* 为什么不直接在 file 进行 update key, 而是append key, 然后再后台线程进行合并和去重呢? (why append only file ? )

因为就算在 SSD 随机读写性能也不好, append only file 很好的利用了这个特性, update key 会造成随机读写. 

* 缺陷
1. hash index 如果不能完全放在内存中, 磁盘随机 IO 会很慢
2. hash index 不能友好的支持范围查询


## SSTables( Sorted string table) and LSM-Trees( Log-Structured Merge-Tree)
* LSM 核心思想

即使有许多微妙的东西，LSM树的基本思想 —— 保存一系列在后台合并的SSTables —— 简
单而有效。即使数据集比可用内存大得多，它仍能继续正常工作。由于数据按排序顺序存
储，因此可以高效地执行范围查询（扫描所有高于某些最小值和最高值的所有键），并且因
为磁盘写入是连续的，所以LSM树可以支持非常高的写入吞吐量。

* SSTables 即 key 是排序的, 跟上面的 hash index 相比好处在哪呢, 

1. 排序之前, 两个 file segments 进行合并, 一个有 n 行, 另一个有 m 行, 合并多个重复的 key, 合并成一个 segment 的时间复杂度是 O(m*n), 排序之后是归并排序, 是 O(m+n)
2. index 不需要保留每个 key, 只需要能断定 key 所在的范围, 再查找
3. 因为一个 index key 能得到一组 key, 所以可以把这一组 key 在存入磁盘前进行压缩. 
那如何使插入的 key 是有序的呢, 使用红黑树和跳表等数据结构,一般都使用跳表作为内存结构，leveldb等 

* 现有的 storage engine 描述如下


1. 写入 key , val 首先到 memTable(红黑树等数据结构)
2. 当 memTable 膨胀到一定程度, 将有序的 key, val, 写入到磁盘 SSTable( 每个 SSTable 对应一个 sparse index(稀疏 index) ? )
3. 读请求的时候, 先查找 memTable, 再按时间顺序倒序查找 SSTable
4. 查找 SSTable 的时候因为key 是分段保存的, 简单来说某个有序的文件只需要保存最大key 和最小key, 然后搜索某个key 先匹配到某个文件, 再在具体文件中二分查找 key
4. 在后台周期性合并 SSTables, 因为同一个时间内只写一个memotable, 然后映射成一个有序的文件, 所以多个文件的key 时间是不一样的不会出现冲突, 保留更新的key即可
5. 为了防止 memTable 的数据在未写入磁盘的时候崩溃, 需要先写 write ahead log
6. 如果查找不存在的key, 在现有的数据结构下代价会很高, 需要先查找 memTable, 因为刚写入的在这里, 按照顺序查, 最新的key 查到了就直接返回, 查不到再依次查找SSTable, 可以使用布隆过滤器, 迅速判断某一个 key 不存在. 
</br>
思想: 一次写操作由一次顺序 IO(WAL log append)和一次内存写就能完成, 大大提升了写性能, 写包括更新和删除, 这两个都是在内存中记一个标记, 待后续合并的时候就知道数据被更新了.

* 为什么一个sstable 文件只需要一个简单的索引呢, 例如最大最小key.


因为你无论如何都要把相关联的key 读到内存中, 在内存中遍历一个几千字节的文件是很快的, 远快于在磁盘中找到这个文件. 

* WAL 日志何时被丢弃

当把memotable 持久化到sstable 时就可以

* 查找不存在的key时间复杂度很高, 要扫描很多文件

可以用bloom 过滤器
## 列式存储
有时候查询只需要一行中的某几列, 若用行存储, 则需要把拥有几百列的几行全部查出来才做过滤, 但是列存储, 把每一列都按照相同行顺序放在一个文件里. (parquet 就是一种列式存储)

列存储还有个好处就是同样的缓存例如cpu的，可以容纳更多的数据

* 列压缩( 96 页 )
适用于列中不同值的数量远小于行数,  将这一列的每一个不同值用位图编码, 每个不同的值分别用一个 bit 数组表示, 如果这个 bit 数组中零很多, 也可以用游程编码(run-length encoded), 进一步减小存储空间.  
例如 id 列 1, 2 , 3, 9
name 列: a, b, c, d
1 这个值对应 bit 数组 [1, 0, 0, 0], 游程编码: 1 个 one, 3 个 zero
2 对应 bit 数组 [0, 1, 0, 0]
a 对应 bit 数组 [1, 0, 0, 0]
where name = "a" and id=2, 将 [0, 1, 0, 0] 与 [1, 0, 0, 0] 按位与, 结果等于 1 的行即返回, 大大减少了存储和传输的带宽.

## B tree VS LSM 


* b+ 树
是在磁盘上维护有序结构的数据结构, key 也是按顺序排列的, 
![image](https://user-images.githubusercontent.com/20329409/212450002-c9c56069-71e2-4f5e-a80a-9cd8d836243d.png)

分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB, 分支因子是分叶子节点的子节点数量.

### B+ 树的优点
适合读多写少; 数据查询性能稳定, 数据都要查找到叶子节点才能返回;在数据量较少的情况下, 只需要一次 IO 就可以返回

### B+ 树的缺点
不适合写入压力大, 并发写入高的场景, 因为修改需要重写整个叶子节点, 同一个 key 并发写入需要加锁或者排队或者 copy on write;
因为写入会写多个叶子节点, 造成磁盘随机写; 虽然可以做范围查找, 但是读如果跨多个叶子节点也是会随机读; 不能放上亿条数据, 否则查找需要多次 IO 比较慢

### LSM 优点
适合写多读少, append 写入, 顺序写入的磁盘性能很高

### LSM 缺点
append 写入, 同一个 key 会有多份数据, 造成存储放大; 而且需要后台 merge ,开销较大会影响性能; 查询延迟大, 如果在memory table 能返回就还好, 否则查询的路径会比较长. 

### 修改数据的区别

B+树, 修改需要读取到叶子节点, 并拿到整个page 并更新; 删除就如果page 已经清空了就需要一些合并之类的; 新建key 的话如果page 满了就需要分割成两个一半的page .
由于B树写要修改原来的page势必并发的时候有竞争，可以采取写时复制的方式，通常会造成写入放大, 不同的 key 造成磁盘随机写. 适合读多写少的场景
</br>
 LSM 是不修改, 只append, 然后合并, 同一个 key 会有多条append 存在, 造成存储放大, 适合写多读少; 而且异步合并的时候开销很大.


### B 树 IO 次数, vs B 树

    * 如何计算B 树的IO 次数呢
 因为B+ 树叶子节点和非叶子节点存储的指针数量不一样, B+ 树不好计算, 时间复杂度跟page 大小无关, 虽然一般16 KB, 但是不懂能存几行数据, 每行的大小未知. 所以一般假设每个page 能存 B 行数据, 那么总共有 N 行, 总的B 树的高度就是 logB N, 以B 为底, 类比二叉树, 就是 (logN) / (logB), 
例如
Say you have a billion rows, and you can currently fit 64 keys in a node. Then the depth of the tree is (log 109)/ log 64 ≈ 30/6 = 5. Now you rebuild the tree with keys half the size and you get log 109 / log 128 ≈ 30/7 = 4.3. Assuming the top 3 levels of the tree are in memory, then you go from 2 disk seeks on average to 1.3 disk seeks on average, for a 35% speedup.
    * 如何计算B+ 树存储的行数呢
    通常三层可以存储千万条数据, 假设每个page 16 KB, 每行1KB, 叶子节点存 16 行, 根节点保留在内存, 三层总条数: 16 * 1000 * 1000 = 一千六百万行, 四层就160 亿行, 保留两层在内存 16MB, 三层 16GB. 
    
</br> 
B+Tree 非叶子节点上是不存储数据的，仅存储键值，数据存储在同一层的叶节点，而B-Tree节点中不仅存储键值，也会存储数据。之所以这么做是因为在数据库中页的大小是固定的，innodb中页的默认大小是16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数(节点的子节点树)就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。另外，B+Tree的阶数是等于键值的数量的，如果B+Tree一个节点可以存储1000个键值，那么4层(包括根节点)B+树可以存储1000×1000×1000=10亿个数据。一般根节点是常驻内存的，所以一般我们查找10亿数据，只需要3次磁盘IO, 每读一个page 算一次磁盘IO, 所以具体几次取决于有几层是放在磁盘上的. 

* WAL , write ahead log 也叫 redo log

用于崩溃恢复, 区别于undo log , 用于事务回滚




* 叶子节点持有左右的指针就可以不用跳回父节点就可以用来做范围查询

### LSM 缺点

Lsm 的缺点就是写入和合并同时进行，在写入很大的时候合并速率慢会占用磁盘空间，且读文件多，合并速率快又影响正常写入
且一个数据可能存在多个地方，事务实现难？为什么，只要有undolog，回滚的时候再写一遍新的值不就好了？
而B树的行为又相对能预测, 而B树的事务能直接找到key所在的page

### 索引
聚簇索引和非聚簇的区别就是实际数据存不存在索引上，非聚簇索引在innodb上是存的主键，再通过主键去聚簇索引里面找行
多列索引，就是把每列的值拼在一起，所以必须按照顺序，且不能中间空一列去查


## 事实表和维度表

事实表中的一些列是属性，例如产品销售的价格和从供应商那里购买的成本(允许计算利润
余额)。事实表中的其他列是对其他表(称为维表)的外键引用。由于事实表中的每一行都
表示一个事件，因此这些维度代表事件的发生地点，时间，方式和原因。



# chapter5_数据复制
## 同步复制和异步复制

## 副本的目的

故障切换; 数据就近读取, 提供读取的并发; 

## 如何复制

基于write ahead log 的多, 实际上是操作日志.

## 如何处理复制延迟, 数据不一致问题. 

> 主从复制

1. 总能读到自己的写入, 读写因果性; 说白了就是该读到的就必须读到. 
2. 单调读, 每次读都能读到上次已经读取到的数据, 可以把每个客户端的读都分到一个副本. 
3. 一致前缀读, 一些有因果相关的写入都分配到同一个副本 .

> 多主复制

实际上貌似目前没有实现真正意义上的对同一份数据进行多主复制, 写入都是要加锁的. 

> 无主复制

## 到底如何能保证读取到最新的值, 或者如何处理数据不一致. 

例如写入了多个节点, 某个节点失效没写入, 那么如何避免读到这个落后节点的数据. 一是可以读所有副本, 并返回最新副本的数据, 用版本号; 
根本原因是你写的时候注重了效率, 等于说需要牺牲读去获取写的性能. 

例如如果写操作在某些副本上成功，而在其他节点上失败(例如，因为某些节点上的磁盘已满),在小于w个副本上写入成功。所以整体判定写入失败, 但整体写入失败并没有在写
入成功的副本上回滚。这意味着如果一个写入虽然报告失败，后续的读取仍然可能会读取这次失败写入的值.


引申为 w(写次数) 和 r(读次数) 与  R(副本数) 的关系. r和w是有效读写所需的最低票数。如果有n个副本, 每个写入必须由w节点确认才能被认为是成功的, 并且我们必
须至少为每个读取查询r个节点。
一个常见的选择是使n为奇数,通常为3或5,并设置 $w = r =(n + 1)/ 2$（向上取整）。但是可以根据需要更改数字。例
如，设置$w = n$和$r = 1$的写入很少且读取次数较多的工作负载可能会受益。这使得读取速
度更快，但具有只有一个失败节点导致所有数据库写入失败的缺点。

# chapter6_分区
## 分区的目的

提供扩展性

## 分区种类

### hash 分区

一致性hash; 

* hash 不能做范围查询, 但是可以用多个字段作为分区查询的key, 第一个字段用作hash 分区, 后续字段用作范围分区, 等于总的分区数是几个分区数的乘积. 组合的方式. 

Cassandra 可以将多个列作为复合主键, 第一个列用作 hash 分区的 key, 后几列用作 range 分区的 key, 当第一列指定的时候, 可以对后几列做范围查询, 例如 key: {userId, update_timestamp} 就很适用
### range 范围分区
某个范围的很有可能有热点, 例如最近的时间或者某个userId
## 如何解决分区的某个key 的热点
加随机数, 但是要记录, 或者遍历所有随机的可能

### 二级索引
就是根据某些关键字段, 非主键的字段构建从该字段到主键的索引, 例如搜索汽车颜色, 根据颜色返回汽车主键, 再通过主键查找汽车.

### 分区再分配的问题
例如某个broker 挂了, 上面的所有replica 都要分配给其他broker. 

* hash 取模

会导致全部分区的数据都要搬迁.

* 固定数量的分区

难以估算正确的数量, 难以应对数据变动大, 

* 动态分区

例如hbase, 分区的数量会随数据变动. 可以进行分区合并和分裂

* 每个节点有固定数量的分区


## 如何路由
请求如何转发到正确的分区, 一是轮训, 二是持有映射关系, 用路由层或者客户端.


# chapter7_事务
## 事务的定义
多个读写操作整合成一个操作的封装, 要么成功要么失败, 不需要管容错和并发的一些问题, 简化了业务需要考虑的问题

## 事务的属性

ACID, A atomic, 原子性, C consistent 一致性, I Isolation 隔离性, D durable 持久性

* 原子性

要么成功, 要么失败可以回滚

* 一致性
    
应该由应用程序来定义什么是它所关注的一致性, 例如会计系统中借贷相抵是数据一致性的体现. 
原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。

* 隔离性

多个事务同时执行的时候, 最后的结果和串行执行的结果一致.

* 持久性 

事务提交成功的时候, 写入的数据就不会丢失了

# chapter8_分布式系统的挑战
* 需要一个集中式的单挑递增, 与时间无关的计数器用于分发事务 ID 等, 因为多节点中, 时间和网络是不可信的, 或者说是很难实际同步的. 
* 该事务或者事件 ID 用于哪里呢: 用于多个客户端写存储的时候判断顺序性, 或者判断租约有效性, 例如当客户端 A 因为 GC 暂停等原因导致进程暂停, 而租约实际已分发到客户端 B (B 的事务 ID 更大) ,  则存储可以拒掉客户端 A 延迟的请求, 因为 A 的事务 ID 已经小于最新的事务 ID . 

# chapter9_一致性与共识
## 线性化
定义: 表现起来像是所有数据只有一个副本, 且所有的操作都是原子的.

约束一: 一旦某个读返回了新值, 后续的所有读不管是不是这个这个客户端, 都必须返回新值

### 线性化的权衡

例如cpu 的多级缓存和主存, 多级缓存数据不一致, 就是为了性能, 不用每次都去主存拿数据. 

## tips

> 多主复制无法确定顺序

> 序列号不一定能正确的反映因果或时间关系, 序列号小的不一定是发生在前. 

> 如何保证一定查询到副本的最新值，可以强制调用所有副本的同步操作

* Lamport 时间戳

可以用来解决如何判断因果顺序. 
每个时间戳由节点id 和计数器值构成, 每次请求都会携带此时间戳, 客户端请求前先向节点 A获取最新时间戳, 并在请求中附带, 然后向节点B 请求时, 如果B 的计数器值小于携带值, 则将B 的计数器值置为携带值加一; 如果计数器值相同则根据节点id 来判断先后

* 如何逐步分析一致性问题

一开始是线性一致, 但是很慢, 性能差, 后续是因果一致性, 是较弱的线性一致性, 因果一致性可以用lambort 时间戳实现, 性能好很多, 但是无法解决并发竞争同一个数据的问题, 例如同时抢占一个事先未注册的用户名, 
最后得出共识需要所有节点一致同意的做决定, 且决定做出就不可撤销, 进而发现这下面一些问题都可以等价于共识问题, 一个问题有答案其他问题答案也能推导出, 例如: 
# chapter10_批处理

### batch processing with unix tools

使Unix工具如此成功的部分原因是，它们使查看正在发生的事情变得非常容易:
Unix命令的输入文件通常被视为不可变的。这意味着你可以随意运行命令，尝试各种命 令行选项，而不会损坏输入文件。
你可以在任何时候结束管道，将管道输出到 less ，然后查看它是否具有预期的形式。这 种检查能力对调试非常有用。 你可以将一个流水线阶段的输出写入文件，并将该文件用作下一阶段的输入。这使你可 以重新启动后面的阶段，而无需重新运行整个管道。


### 对象存储和 hdfs 的区别

 一个不同之处在于，对于HDFS，可以将计算任务安排在存储特定文件副本的计算机 上运行，而对象存储通常将存储和计算分开。如果网络带宽是一个瓶颈，从本地磁盘读 取有性能优势。但是请注意，如果使用纠删码，则会丢失局部性，因为来自多台机器的 数据必须进行合并以重建原始文件

### 批处理中使用 join
大表和小表的链接, 用户 id 来自大表的数据, 用户数据库是小表.

### 常用的 join 方式
例如一个大表是用户活动事件表 A , 包括用户 id 和用户时间; 小表是用户表 B, 包括用户 id 和用户信息; 通过用户 id 做连接; 需要解决的问题是大表放不进内存中, 小表有可能放的进, 有可能放不进. 
* 广播小表
大表做分区放在多台机器, 小表广播到每台机器的内存里, 适合小表比较小, 小表在内存中就做成一个 hashmap, 

* bucketed map joins

大表和小表的把相同的 key 都抽到同一台机器, 等于两个表的 key 都做 hash 取余, 相同的 key 肯定会在同一台机器的.

* sort merge join

把大表和小表都按照 userid 排序, 然后两个表比较, 取用户表 B 最小的 userId 那条记录, 放到做 join 的那台机器内存中, 每次只需要放一条就够了, 一直流式输入B 表的记录, 直到 userid 匹配, 然后输出join 结果到文件上, 然后 B 表 userId 往后移, 直到和 A 表的下一个 userId 匹配, 再输出结果到文件, 以此类推.

#### 为什么要把数据靠近计算
实现这一连接的最简单方法是，逐个遍历活动事件，并为每个遇到的用户ID查询用户数据库 (在远程服务器上)。这是可能的，但是它的性能可能会非常差:处理吞吐量将受限于受数据库服务器的往返时间，本地缓存的有效性很大程度上取决于数据的分布，并行运行大量查询可能会轻易压垮数据库【35】。
</br>
为了在批处理过程中实现良好的吞吐量，计算必须(尽可能)限于单台机器上进行。为待处 理的每条记录发起随机访问的网络请求实在是太慢了。而且，查询远程数据库意味着批处理 作业变为非确定的(nondeterministic)，因为远程数据库中的数据可能会改变。
​ 因此，更好的方法是获取用户数据库的副本(例如，使用ETL进程从数据库备份中提取数 据，参阅“数据仓库”)，并将它和用户行为日志放入同一个分布式文件系统中。然后你可以将 用户数据库存储在HDFS中的一组文件中，而用户活动记录存储在另一组文件中，并能用 MapReduce将所有相关记录集中到同一个地方进行高效处理。
</br>
在排序合并连接中，Mapper和排序过程确保了所有对特定用户ID执行连接操作的必须数据都 被放在同一个地方:单次调用Reducer的地方。预先排好了所有需要的数据，Reducer可以是 相当简单的单线程代码，能够以高吞吐量和与低内存开销扫过这些记录。


​ 我们在“全文搜索和模糊索引”中简要地了解了Lucene这样的全文搜索索引是如何工作的:它是一个文件(关键词字典)，你可以在其中高效地查找特定关键字，并找到包含该关键字的 所有文档ID列表(文章列表)。这是一种非常简化的看法 —— 实际上，搜索索引需要各种额 外数据，以便根据相关性对搜索结果进行排名，纠正拼写错误，解析同义词等等 —— 但这个 原则是成立的。


