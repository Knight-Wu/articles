# chapter10_批处理

### batch processing with unix tools

使Unix工具如此成功的部分原因是，它们使查看正在发生的事情变得非常容易:
Unix命令的输入文件通常被视为不可变的。这意味着你可以随意运行命令，尝试各种命 令行选项，而不会损坏输入文件。
你可以在任何时候结束管道，将管道输出到 less ，然后查看它是否具有预期的形式。这 种检查能力对调试非常有用。 你可以将一个流水线阶段的输出写入文件，并将该文件用作下一阶段的输入。这使你可 以重新启动后面的阶段，而无需重新运行整个管道。


### 对象存储和 hdfs 的区别

 一个不同之处在于，对于HDFS，可以将计算任务安排在存储特定文件副本的计算机 上运行，而对象存储通常将存储和计算分开。如果网络带宽是一个瓶颈，从本地磁盘读 取有性能优势。但是请注意，如果使用纠删码，则会丢失局部性，因为来自多台机器的 数据必须进行合并以重建原始文件

### 批处理中使用 join
大表和小表的链接, 用户 id 来自大表的数据, 用户数据库是小表.

### 常用的 join 方式
例如一个大表是用户活动事件表 A , 包括用户 id 和用户时间; 小表是用户表 B, 包括用户 id 和用户信息; 通过用户 id 做连接; 需要解决的问题是大表放不进内存中, 小表有可能放的进, 有可能放不进. 
* 广播小表
大表做分区放在多台机器, 小表广播到每台机器的内存里, 适合小表比较小, 小表在内存中就做成一个 hashmap, 

* bucketed map joins

大表和小表的把相同的 key 都抽到同一台机器, 等于两个表的 key 都做 hash 取余, 相同的 key 肯定会在同一台机器的.

* sort merge join

把大表和小表都按照 userid 排序, 然后两个表比较, 取用户表 B 最小的 userId 那条记录, 放到做 join 的那台机器内存中, 每次只需要放一条就够了, 一直流式输入B 表的记录, 直到 userid 匹配, 然后输出join 结果到文件上, 然后 B 表 userId 往后移, 直到和 A 表的下一个 userId 匹配, 再输出结果到文件, 以此类推.

#### 为什么要把数据靠近计算
实现这一连接的最简单方法是，逐个遍历活动事件，并为每个遇到的用户ID查询用户数据库 (在远程服务器上)。这是可能的，但是它的性能可能会非常差:处理吞吐量将受限于受数据库服务器的往返时间，本地缓存的有效性很大程度上取决于数据的分布，并行运行大量查询可能会轻易压垮数据库【35】。
</br>
为了在批处理过程中实现良好的吞吐量，计算必须(尽可能)限于单台机器上进行。为待处 理的每条记录发起随机访问的网络请求实在是太慢了。而且，查询远程数据库意味着批处理 作业变为非确定的(nondeterministic)，因为远程数据库中的数据可能会改变。
​ 因此，更好的方法是获取用户数据库的副本(例如，使用ETL进程从数据库备份中提取数 据，参阅“数据仓库”)，并将它和用户行为日志放入同一个分布式文件系统中。然后你可以将 用户数据库存储在HDFS中的一组文件中，而用户活动记录存储在另一组文件中，并能用 MapReduce将所有相关记录集中到同一个地方进行高效处理。
</br>
在排序合并连接中，Mapper和排序过程确保了所有对特定用户ID执行连接操作的必须数据都 被放在同一个地方:单次调用Reducer的地方。预先排好了所有需要的数据，Reducer可以是 相当简单的单线程代码，能够以高吞吐量和与低内存开销扫过这些记录。


​ 我们在“全文搜索和模糊索引”中简要地了解了Lucene这样的全文搜索索引是如何工作的:它是一个文件(关键词字典)，你可以在其中高效地查找特定关键字，并找到包含该关键字的 所有文档ID列表(文章列表)。这是一种非常简化的看法 —— 实际上，搜索索引需要各种额 外数据，以便根据相关性对搜索结果进行排名，纠正拼写错误，解析同义词等等 —— 但这个 原则是成立的。


