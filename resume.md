### 吴桐的简历
### 联系方式
- 手机：17688748581
- Email：1239562508guge@gmail.com 


### 个人信息

 - 吴桐/男/1993.8 
 - 本科/东南大学/软件工程，2016.7毕业
 - 工作年限：3年
 - github: https://github.com/Knight-Wu

### 能力
>在业余时间总结所学所会, 维护了一个 blog:https://github.com/Knight-Wu/articles ，熟练使用并清楚大部分原理, 包括spark, hdfs, hbase, kafka等; 具备大数据环境下较强的故障追踪能力和调优经验, 给数仓解决过多个生产问题, 极大提高了稳定性；熟练使用java，包括 dubbo, logback, spring, maven, 具有丰富的高并发的开发经验; 熟练使用 golang，包括 prometheus, grafana. 强烈的好胜心和求知欲，善于在工作解决实际问题和各种报错，善于读源码排查问题，工作效率较高。可流畅阅读英文论文和文档。


<br />
<br />

### 工作经历     

####  Shopee - 虾皮信息科技有限公司 （ 2019 年 5 月 ~  至今 ）
主要使用 Java ，Golang

##### Sinker
 1. 自研的从 Kafka 批量写入 Hdfs 的组件，实现了 exactly once ，为了解决 Flume 在处理埋点等大数据量的时候经常会有百分之十的数据丢失和文件 eof 问题，该问题团队在半年时间内没有定位和解决问题，能容忍 hdfs 和 kafka 集群异常，大促期间每天数据将近 100TB，上线的一年时间里没有出现过数据不精确问题
 2. 通过重试解决网络波动等问题；利用 Hdfs rename 原子性，将 offset 和文件长度保存在文件名，解决 hdfs 集群暂时故障时卡住，恢复时能排除可能的 eof 等异常文件。

##### Spark Monitor
1. graphite-exporter 收集 spark 原生的指标到 prometheus 监控，并展示到 grafana，可以查看spark 应用运行过程中的 cpu，memory，spark event 等各种信息，方便排查问题。
2. 通过修改spark 源码，增加了应用名和机器名字段，可以做应用和机器维度的指标聚合，例如查看应用的每天执行情况，查看某些耗时高于平均的机器。

##### Business Insight
1. 类似于淘宝的生意参谋，给卖家提供数据分析和报表，例如 GMV 和销量等。
2. 负责从 Kafka 获取实时数据并写入 redis，提供实时查询；从 ElasticSearch 获取历史数据，数仓负责写入（也做过两三个需求的数仓开发），提供历史的聚合查询，例如过去三十天等。

##### DBQuery
1. 在配置页面通过配置 sql 和 udf 等，提供 http 接口，实现对 hbase，elasticSearch，mysql 的查询。目的是将团队内的查询数据库的需求都集中到一个系统，仅通过配置，不需要走传统的开发测试流程，减轻类似需求的开发时间，方便排查问题，把控 sql 质量，减轻对数据库的压力。
2. 具有鉴权，限流，熔断等功能，保证系统不被恶意请求和单个业务请求压垮。

#### 招联消费金融有限公司 （ 2016 年 7 月 ~ 2019 年 5 月 ）
主要使用 Java
##### 维护大数据集群
1. 负责生产和测试环境大数据集群的日常维护, 配置调优，保证集群的高可用性和高性能, 解决业务部门使用大数据的各类技术难题, 例如:解决了公司基础数据组使用hive on spark跑批时的数个生产故障

##### 数据应用等系统
1. 使用 spark，hbase，hive 给客户营销系统做客群筛选和数据营销，提供离线和准实时查询。

##### 公司级的基础框架
1. 基于 dubbo 封装的远程调用框架，增加了基于分数的负载均衡、模拟正常请求的心跳并返回提供者信息等功能


> Written with [StackEdit](https://stackedit.io/).
