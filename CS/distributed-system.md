 分布式系统的设计
可以参考es 如何基于lucene 构建分布式搜索引擎的
单机存储随着业务的增长会遇到性能与单点故障问题。通常有两种解决方案：

* 数据分布

就是把数据分块存在不同的服务器上（分库分表）, 解决单机性能问题. 常见的有hash 分布, 范围分布

* 数据复制

让所有的服务器都有相同的数据，提供相当的服务, 一是容错, 二是提供读的并发, 三是可以多个副本可以提供更近的数据.
有主从复制, 和对等复制. es 数据复制由写入节点并发向多个副本写入, 多个副本能扩展读的能力

* cap 理论

在理論計算機科學中，CAP定理（CAP theorem），又被稱作布魯爾定理（Brewer's theorem），它指出對於一個分布式计算系統來說，不可能同時滿足以下三點：[1][2]

一致性（Consistency） （等同于所有节点访问同一份最新的数据副本）
可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）
分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。）
根據定理，分佈式系統只能滿足三項中的兩項而不可能滿足全部三項[4]。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。

CAP有时以这种面目出现：一致性，可用性和分区容错性：三者只能择其二。不幸的是
这种说法很有误导性，因为网络分区是一种错误，所以它并不是一个选项：不管
你喜不喜欢它都会发生。
在网络正常工作的时候，系统可以提供一致性（线性一致性）和整体可用性。发生网络
故障时，你必须在线性一致性和整体可用性之间做出选择。

举例: 例如kafka 有个配置是unclean.leader, 允许数据不完整的副本成为leader, 如果你设置了这个配置等于舍弃了一致性, 增加了可用性; 反之就保证了一致性, 但降低了可用性. 
* 两阶段提交

如果第二阶段提交时, 有节点回复失败, 要回滚, 然后此时有部分节点又回滚失败了呢? 多个节点数据不一致, 只要大多数节点是一致的就是可用的? 

* lucene 写入过程

1. 先写memotable , 做校验, 然后再写log 记录操作, 保证数据多份, 然后返回客户端成功
2. memotable 达到一定大小持久化成segment(这个过程叫refresh), 最后刷到磁盘之后才清空log
3. 要形成segment 之后才能够做全文搜索, 这时候才构建索引, 否则只能根据docId 搜索memotable. docId 只在单个shard 内唯一, 多个shard 有可能重复
4. segment 也是append only 的模式, 不能改的, 类似LSM, segment 数量太多会合并 merge, 小文件会影响性能. 

* es 数据分布

index 可以理解为用于业务上的定义一批数据, routing 字段用于数据在多个shard 分布, 默认hash, routing 字段默认是doc_id.
shard 可能包含多个或一个(合并后)lucene segment, shard 可以理解为es 对lucene segment 的封装, 只能存在于单台机器, 多个shard 就组成了一个分布式的存储, 解决性能问题. 

* es 数据一致性如何保证

A "primary shard" is the main home for a document. A "replica shard" is a copy of the primary shard that provides (1) failover in case the primary dies and (2) increased read throughput

### CAP定理
三个原则只能最多满足两个
* Consistency 一致性
意思是，写操作之后的读操作，必须返回该值。
* Partition tolerance 分区容错性
大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。**可以认为P 是一定要满足的, 所以 C 和A 只能满足一个**

* Availability 
中文叫做"可用性"，意思是只要收到用户的请求，服务器就必须给出回应。

*  Consistency 和 Availability 的矛盾
多台服务器在数据同步的过程中, server 1 在向server 2 同步数据的时候, 必须锁住server 2, 否则可能读出不一致的数据, 当同步完成之后才能开放server 2的服务. 

* 在什么场合，可用性高于一致性？
举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。
一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。

### BASE 定理
Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)三个短语的缩写。是对CAP中AP的一个扩展

1.  基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。
2.  软状态:允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是CAP中的不一致。
3.  最终一致:最终一致是指经过一段时间后，所有节点数据都将会达到一致。

在BASE中用软状态和最终一致，保证了延迟后的一致性。BASE和 ACID 是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。

### 两阶段提交协议 2PC
必须满足如下前提条件: 
a. 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上 
b. 所有节点不会永久性损坏，即使损坏后仍然可以恢复。 

1. 第一阶段(投票阶段):
a. 协调者询问工作者是否可以执行提交操作, 并等待响应
b. 工作者执行事务操作, 并记录所有的undo和redo 日志
c. 工作者返回协调者事务是否成功的消息
2. 第二阶段(提交):
当工作者返回的消息均为事务成功的话,
a. 协调者向各个工作者发出"提交" 的请求
b. 工作者完成事务, 并释放资源
**工作者完成事务 跟1.b 的执行事务有何区别, 到底数据什么时候可见 ?** 
commit 之后可见, 执行事务只是执行写入, 中间阶段的可见性取决于事务的隔离级别, 提交事务后才会具体可见.
c. 工作者发送完成的消息给协调者
d. 协调者收到完成的消息后, 完成事务

如果任一工作者返回事务失败的消息, 或者协调者无法收到事务的消息时: 
a. 协调者发出回滚的请求
b. 工作者根据undo 日志, 回滚, 并释放资源
c. 工作者发送回滚完成给协调者, 
d. 协调者收到回滚完成, 取消事务

* 缺点
需要在协调者和工作者间加入超时机制;
若协调者在发出事务commit 消息后down, 并且接受到commit 消息的工作者也down, 则事务状态永远未知;
协调者需要高可用, 需要基于paxos 算法原理保证高可用. 

#### 三阶段提交协议 3PC
相当于比两阶段提交协议多了超时的控制, 并且在一和二阶段间加入一个询问阶段, 保证工作者的状态是可以完成事务的. 
具体分为 canCommit, preCommit, doCommit

### 分布式事务的实现
https://juejin.im/post/5aa3c7736fb9a028bb189bca
#### 基于支持分布式事务的可靠的消息框架
感觉分布式事务的实现关键在于redo 和undo 日志, 并能保证持久化, 如下图, 如果下游系统B, 接受到消息并执行成功, 数据已经改变, 但是返回ack 的时候失败, 那么数据如何回滚呢, 因为B 系统的历史数据无法恢复, 等于说B 系统的redo可以由消息保证, 但是undo 如果保证呢, B 系统的回滚如何实现? 
![enter image description here](https://drive.google.com/uc?id=1Uw3j4tYZl5TwH_QYlPus0BKNIN9fD02g)


